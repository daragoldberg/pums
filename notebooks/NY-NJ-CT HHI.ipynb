{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using IPUMS records, calculate in-migration and out-migration to/from NYC - NYC Metro and domestic U.S.\n",
    "\n",
    "Requires download of csv extracts from IPUMS USA website\n",
    "https://usa.ipums.org\n",
    "\n",
    "For more information about specific variables available for download, refer to IPUMS-USA website, ex.:\n",
    "https://usa.ipums.org/usa-action/variables/MIGRATE1#codes_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stat functions for using replicate weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to calculate standard error, moe, and coefficient of variation\n",
    "def get_se(per_wt,rep_weights):\n",
    "    result = math.sqrt((sum(map(lambda x: (x-per_wt)**2,rep_weights))/20))\n",
    "    return result\n",
    "\n",
    "def get_moe(se):\n",
    "    return se*1.645 #90% confidence interval\n",
    "\n",
    "def agg_moe(m):\n",
    "    result = math.sqrt(sum(map(lambda x: x**2, m)))\n",
    "    return result\n",
    "\n",
    "def get_cv(est,m):\n",
    "    if est == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (np.absolute(m/1.645/est))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of replicate weights\n",
    "repwt = 'REPWTP'\n",
    "repwts = [repwt+str(i) for i in range(1, 81)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geography look up files & cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull in geography reference files\n",
    "df = pd.read_csv('data/usa_00046.csv')\n",
    "respuma_00 = pd.read_csv('data/respuma_xwalk_00.csv')\n",
    "respuma_10 = pd.read_csv('data/respuma_xwalk_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MULTYEAR</th>\n",
       "      <th>SAMPLE</th>\n",
       "      <th>SERIAL</th>\n",
       "      <th>CBSERIAL</th>\n",
       "      <th>HHWT</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>STATEFIP</th>\n",
       "      <th>COUNTYFIP</th>\n",
       "      <th>PUMA</th>\n",
       "      <th>STRATA</th>\n",
       "      <th>GQ</th>\n",
       "      <th>HHINCOME</th>\n",
       "      <th>PERNUM</th>\n",
       "      <th>PERWT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200001</td>\n",
       "      <td>436195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2000004361951</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>55600</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200001</td>\n",
       "      <td>436195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2000004361951</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>55600</td>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200001</td>\n",
       "      <td>436195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2000004361951</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>55600</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200001</td>\n",
       "      <td>436195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2000004361951</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>55600</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200001</td>\n",
       "      <td>436195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2000004361951</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>55600</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  MULTYEAR  SAMPLE  SERIAL  CBSERIAL  HHWT        CLUSTER  STATEFIP  \\\n",
       "0  2000       NaN  200001  436195       NaN  13.0  2000004361951        34   \n",
       "1  2000       NaN  200001  436195       NaN  13.0  2000004361951        34   \n",
       "2  2000       NaN  200001  436195       NaN  13.0  2000004361951        34   \n",
       "3  2000       NaN  200001  436195       NaN  13.0  2000004361951        34   \n",
       "4  2000       NaN  200001  436195       NaN  13.0  2000004361951        34   \n",
       "\n",
       "   COUNTYFIP  PUMA  STRATA  GQ  HHINCOME  PERNUM  PERWT  \n",
       "0          1   101      56   1     55600       1   11.0  \n",
       "1          1   101      56   1     55600       2   11.0  \n",
       "2          1   101      56   1     55600       3    8.0  \n",
       "3          1   101      56   1     55600       4    9.0  \n",
       "4          1   101      56   1     55600       5    8.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "respuma_00.GISMATCH= respuma_00.GISMATCH.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new id columns for merge with geo lookup tables\n",
    "df['stpuma_id'] = df['STATEFIP'].apply(str) + \\\n",
    "                    df['PUMA'].apply(str).apply(lambda x: '{0:0>5}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR           int64\n",
       "MULTYEAR     float64\n",
       "SAMPLE         int64\n",
       "SERIAL         int64\n",
       "CBSERIAL     float64\n",
       "HHWT         float64\n",
       "CLUSTER        int64\n",
       "STATEFIP       int64\n",
       "COUNTYFIP      int64\n",
       "PUMA           int64\n",
       "STRATA         int64\n",
       "GQ             int64\n",
       "HHINCOME       int64\n",
       "PERNUM         int64\n",
       "PERWT        float64\n",
       "stpuma_id     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce to just primary householder to de-dupe records\n",
    "df = df[df['PERNUM']==1]\n",
    "df_00 = df[df.YEAR==2000]\n",
    "df_10 = df[df.YEAR==2010]\n",
    "df_18 = df[df.YEAR==2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MULTYEAR</th>\n",
       "      <th>SAMPLE</th>\n",
       "      <th>SERIAL</th>\n",
       "      <th>CBSERIAL</th>\n",
       "      <th>HHWT</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>STATEFIP</th>\n",
       "      <th>COUNTYFIP</th>\n",
       "      <th>PUMA</th>\n",
       "      <th>STRATA</th>\n",
       "      <th>GQ</th>\n",
       "      <th>HHINCOME</th>\n",
       "      <th>PERNUM</th>\n",
       "      <th>PERWT</th>\n",
       "      <th>stpuma_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200001</td>\n",
       "      <td>436195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2000004361951</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>55600</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3400101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200001</td>\n",
       "      <td>436196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2000004361961</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>6750</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3400101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200001</td>\n",
       "      <td>436198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2000004361981</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6500</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3400101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200001</td>\n",
       "      <td>436200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2000004362001</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>63500</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3400101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200001</td>\n",
       "      <td>436202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2000004362021</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>140700</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3400101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR  MULTYEAR  SAMPLE  SERIAL  CBSERIAL  HHWT        CLUSTER  STATEFIP  \\\n",
       "0   2000       NaN  200001  436195       NaN  13.0  2000004361951        34   \n",
       "5   2000       NaN  200001  436196       NaN  22.0  2000004361961        34   \n",
       "6   2000       NaN  200001  436198       NaN  19.0  2000004361981        34   \n",
       "7   2000       NaN  200001  436200       NaN  52.0  2000004362001        34   \n",
       "12  2000       NaN  200001  436202       NaN  14.0  2000004362021        34   \n",
       "\n",
       "    COUNTYFIP  PUMA  STRATA  GQ  HHINCOME  PERNUM  PERWT stpuma_id  \n",
       "0           1   101      56   1     55600       1   11.0   3400101  \n",
       "5           1   101     105   1      6750       1   17.0   3400101  \n",
       "6           1   101      80   1      6500       1   14.0   3400101  \n",
       "7           1   101      62   1     63500       1   52.0   3400101  \n",
       "12          1   101      93   1    140700       1   22.0   3400101  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_00 = df_00.merge(respuma_00,how='left',left_on='stpuma_id',right_on='GISMATCH')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_00['HHI_18'] = reg_00['HHINCOME'].apply(lambda x: x*1.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_sort = lambda x: '<$50k' if (x >= 0 and x<50000) else '$50k-$100k' if (x >= 50000 and x < 100000) else '>$100k' if x >= 100000 else 'NA'\n",
    "reg_00['HHI_18_cat'] = reg_00['HHI_18'].apply(inc_sort)\n",
    "reg_00 = reg_00[reg_00['HHINCOME'] != 9999999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MULTYEAR</th>\n",
       "      <th>SAMPLE</th>\n",
       "      <th>SERIAL</th>\n",
       "      <th>CBSERIAL</th>\n",
       "      <th>HHWT</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>STATEFIP_x</th>\n",
       "      <th>COUNTYFIP</th>\n",
       "      <th>PUMA_x</th>\n",
       "      <th>...</th>\n",
       "      <th>StateName</th>\n",
       "      <th>STATEFIP_y</th>\n",
       "      <th>PUMA_y</th>\n",
       "      <th>GISJOIN</th>\n",
       "      <th>GISMATCH</th>\n",
       "      <th>CountyCode</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>Subregion</th>\n",
       "      <th>HHI_18</th>\n",
       "      <th>HHI_18_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200001</td>\n",
       "      <td>436195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2000004361951</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80620.0</td>\n",
       "      <td>$50k-$100k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200001</td>\n",
       "      <td>436196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2000004361961</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9787.5</td>\n",
       "      <td>&lt;$50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200001</td>\n",
       "      <td>436198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2000004361981</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9425.0</td>\n",
       "      <td>&lt;$50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200001</td>\n",
       "      <td>436200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2000004362001</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92075.0</td>\n",
       "      <td>$50k-$100k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200001</td>\n",
       "      <td>436202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2000004362021</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>204015.0</td>\n",
       "      <td>&gt;$100k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  MULTYEAR  SAMPLE  SERIAL  CBSERIAL  HHWT        CLUSTER  STATEFIP_x  \\\n",
       "0  2000       NaN  200001  436195       NaN  13.0  2000004361951          34   \n",
       "1  2000       NaN  200001  436196       NaN  22.0  2000004361961          34   \n",
       "2  2000       NaN  200001  436198       NaN  19.0  2000004361981          34   \n",
       "3  2000       NaN  200001  436200       NaN  52.0  2000004362001          34   \n",
       "4  2000       NaN  200001  436202       NaN  14.0  2000004362021          34   \n",
       "\n",
       "   COUNTYFIP  PUMA_x  ...  StateName  STATEFIP_y  PUMA_y  GISJOIN  GISMATCH  \\\n",
       "0          1     101  ...        NaN         NaN     NaN      NaN       NaN   \n",
       "1          1     101  ...        NaN         NaN     NaN      NaN       NaN   \n",
       "2          1     101  ...        NaN         NaN     NaN      NaN       NaN   \n",
       "3          1     101  ...        NaN         NaN     NaN      NaN       NaN   \n",
       "4          1     101  ...        NaN         NaN     NaN      NaN       NaN   \n",
       "\n",
       "  CountyCode CountyName  Subregion    HHI_18  HHI_18_cat  \n",
       "0        NaN        NaN        NaN   80620.0  $50k-$100k  \n",
       "1        NaN        NaN        NaN    9787.5       <$50k  \n",
       "2        NaN        NaN        NaN    9425.0       <$50k  \n",
       "3        NaN        NaN        NaN   92075.0  $50k-$100k  \n",
       "4        NaN        NaN        NaN  204015.0      >$100k  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_00.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.pivot_table(reg_00,values='HHWT',index='CountyCode',columns=['HHI_18_cat'],aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_excel('test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# REDUCE DATA TABLE TO PEOPLE WHO HAVE MOVED TO NYC COUNTIES ONLY IN THE LAST YEAR\n",
    "\n",
    "# Select only records for people who have moved in the last year\n",
    "# MIGRATE1 == 2,3,4 ; other codes are people who haven't moved\n",
    "mig_codes = [2,3,4]\n",
    "df = df[df['MIGRATE1'].isin(mig_codes)]\n",
    "\n",
    "\n",
    "# Select records for people who live in NYC currently\n",
    "nyc = ['36005','36047','36061','36081','36085']\n",
    "df = df[df['in_stco'].isin(nyc)]\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with geography look up tables \n",
    "df_in = df.merge(df_migpl,how='left',left_on='MIGPLAC1',right_on='migplac_id').merge(df_migpuma,how='left',left_on='migpuma_id',right_on='MIGPUMA_str')\n",
    "#df_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN values in aggregation columns with domestic/intl values\n",
    "column_clean = ['Subregion5','Subregion7','County','CountyFIP']\n",
    "for i in column_clean:\n",
    "    df_in.loc[df_in[i].isnull(),i] = df_in['US_intl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce table to just counties and subregions of residence 1 year ago\n",
    "cols = ['in_stco','County','CountyFIP','Subregion7','Subregion5','PERWT'] + repwts\n",
    "df_in = df_in[cols]\n",
    "\n",
    "# rename for clarity\n",
    "df_in = df_in.rename(columns={'County':'out_co_name','CountyFIP':'out_stco',\\\n",
    "                              'Subregion5':'out_subreg_5','Subregion7':'out_subreg_7',\\\n",
    "                              'PERWT':'in_pop'})\n",
    "    \n",
    "df_in.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NYC total by Subregion of Origin (simplified) table\n",
    "\n",
    "Select different summary columns in groupby function to choose counties or aggregation by borough of current residence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_in = df_in.groupby('out_subreg_5').sum().reset_index()\n",
    "#dff_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate standard error, margin of error, cv\n",
    "# drop replicate weight columns\n",
    "dff_in['in_se'] = dff_in.apply(lambda x: (get_se(x['in_pop'],x[repwts])),axis=1)\n",
    "dff_in['in_moe'] = dff_in.apply(lambda x: (get_moe(x['in_se'])),axis=1)\n",
    "dff_in['in_cv'] = dff_in.apply(lambda x: (get_cv(x['in_pop'],x['in_se'])),axis=1)\n",
    "\n",
    "dff_in = dff_in.drop(columns=repwts) \n",
    "                            \n",
    "dff_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NYC resident out-migration to NYC Metro and U.S.\n",
    "\n",
    "##### update csv paths & keep aggregation geography consistent with previous for net flow table in following section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull in outflow table\n",
    "dff = pd.read_csv('data/nyc_outflow_110620.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new id columns for merge with geo lookup table\n",
    "dff['in_respuma'] = dff['STATEFIP'].apply(str).apply(lambda x: '{0:0>3}'.format(x)) + \\\n",
    "                    dff['PUMA'].apply(str).apply(lambda x: '{0:0>5}'.format(x))\n",
    "\n",
    "dff['out_stco'] = dff['MIGPLAC1'].apply(str).apply(lambda x: '{0:0>2}'.format(x)) + \\\n",
    "                   dff['MIGCOUNTY1'].apply(str).apply(lambda x: '{0:0>3}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select records only for people who lived in NYC one year ago (NYC out-migrants)\n",
    "dff = dff[dff['out_stco'].isin(nyc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with geography look up tables \n",
    "df_out = dff.merge(df_respuma,how='left',left_on='in_respuma',right_on='puma_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN values in aggregation columns with US for non region\n",
    "column_clean = ['NAME','Subregion','Subregion2','County','CountyFIPS']\n",
    "for i in column_clean:\n",
    "    df_out.loc[df_out[i].isnull(),i] = 'US'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reduce table to just current counties and subregions of residence \n",
    "cols = ['County','CountyFIPS','Subregion','Subregion2','out_stco','PERWT'] + repwts\n",
    "df_out = df_out[cols]\n",
    "\n",
    "# rename for clarity\n",
    "df_out = df_out.rename(columns={'County':'in_co_name','CountyFIPS':'in_stco',\\\n",
    "                              'Subregion':'in_subreg_7','Subregion2':'in_subreg_5',\\\n",
    "                              'PERWT':'out_pop'})\n",
    "    \n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NYC total outflow by Subregion Destination (simplified) table\n",
    "\n",
    "Select different summary columns in groupby function to choose counties or aggregation by borough of previous residence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_out = df_out.groupby('in_subreg_5').sum().reset_index()\n",
    "#dff_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate standard error, margin of error, cv\n",
    "# drop replicate weight columns\n",
    "dff_out['out_se'] = dff_out.apply(lambda x: (get_se(x['out_pop'],x[repwts])),axis=1)\n",
    "dff_out['out_moe'] = dff_out.apply(lambda x: (get_moe(x['out_se'])),axis=1)\n",
    "dff_out['out_cv'] = dff_out.apply(lambda x: (get_cv(x['out_pop'],x['out_se'])),axis=1)\n",
    "\n",
    "dff_out = dff_out.drop(columns=repwts) \n",
    "                            \n",
    "dff_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge in & out to create net flow columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net = pd.merge(dff_in,dff_out,how='left',left_on='out_subreg_5',right_on='in_subreg_5')\n",
    "df_net = df_net.replace(np.nan,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net['net_pop'] = df_net['in_pop']-df_net['out_pop']\n",
    "df_net['net_moe'] = df_net.apply(lambda x: (agg_moe(x[['in_moe','out_moe']])),axis=1)\n",
    "df_net['net_cv'] = df_net.apply(lambda x: (get_cv_2(x['net_pop'],x['net_moe'])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net.to_excel('output/nyc_subregion_migration_1418.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
